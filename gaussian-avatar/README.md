# Gaussian Avatar — Real-Time Conversation

Self-hosted real-time avatar conversation system using **Gaussian splatting** rendered in the browser. Built on [OpenAvatarChat](https://github.com/HumanAIGC-Engineering/OpenAvatarChat) + [LAM (Large Avatar Model)](https://github.com/aigc3d/LAM).

## Architecture

```
Browser (WebGL Gaussian Renderer)
    |  WebRTC audio/data
    v
OpenAvatarChat Server (Docker)
    |
    +-- SileroVAD ......... voice activity detection
    +-- SenseVoice ........ speech-to-text (local GPU)
    +-- LLM ............... OpenAI / Qwen / Ollama
    +-- EdgeTTS ........... text-to-speech (free)
    +-- LAM Audio2Exp ..... audio -> facial expressions
    |
    v
Browser receives expression coefficients,
animates Gaussian avatar at 60+ FPS client-side
```

The LAM avatar is rendered entirely in the browser via WebGL. The server only sends expression coefficients over WebRTC, so bandwidth is minimal and multiple users can connect simultaneously.

## Requirements

- **GPU**: NVIDIA with CUDA 12.2+ (tested on RTX 3090/4090)
  - VRAM: ~4-6 GB (SenseVoice ASR + Audio2Expression)
  - CPU-only mode possible for LAM client (slower ASR)
- **Docker**: Docker Engine 24+ with [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)
- **Disk**: ~3 GB (models + Docker image)
- **OS**: Linux (recommended), Windows with WSL2
- **API keys**: OpenAI API key (or DashScope, or local Ollama)

## Quick Start

```bash
# 1. Clone and enter the directory
cd gaussian-avatar

# 2. Run setup (downloads models, generates SSL certs)
bash scripts/setup.sh

# 3. Add your API key
#    Edit .env and set OPENAI_API_KEY=sk-...
nano .env

# 4. Build and run
docker compose up --build

# 5. Open in browser
#    https://localhost:8282
#    (Accept the self-signed certificate warning)
```

## Configuration

### LLM Provider

Edit `config/chat_with_lam.yaml` under `LLMOpenAICompatible`:

| Provider | api_url | model_name | API Key |
|----------|---------|------------|---------|
| OpenAI | `https://api.openai.com/v1` | `gpt-4o-mini` | `OPENAI_API_KEY` |
| DashScope (Qwen) | `https://dashscope.aliyuncs.com/compatible-mode/v1` | `qwen-plus` | `DASHSCOPE_API_KEY` |
| Ollama (local) | `http://host.docker.internal:11434/v1` | `llama3.2` | (none) |

### TTS Provider

The default config uses **EdgeTTS** (free, no API key). For higher quality, switch to CosyVoice by uncommenting the `CosyVoice` section and commenting out `EdgeTTS` in the config.

### Custom Avatar

LAM ships with sample assets in `src/handlers/client/h5_rendering_client/lam_samples/`. To use a custom avatar:

1. Generate a Gaussian avatar using [LAM](https://github.com/aigc3d/LAM) from a single photo
2. Export as `.zip` file
3. Place in the models directory
4. Update `asset_path` in `config/chat_with_lam.yaml`

### Concurrent Sessions

The `concurrent_limit: 5` setting controls how many simultaneous conversations the server supports. Each session uses ~0.5-1 GB additional VRAM.

## Networking

| Access | SSL | TURN | Setup |
|--------|-----|------|-------|
| Localhost only | Optional | No | Just run `docker compose up` |
| LAN access | Required | No | SSL certs generated by setup.sh |
| Internet access | Required | Required | Configure coturn with real certs |

The setup script generates self-signed SSL certs and a basic coturn TURN server config. For production internet access, replace with real certificates and configure your firewall.

## Model Downloads

The `scripts/setup.sh` script downloads:

| Model | Size | Purpose |
|-------|------|---------|
| wav2vec2-base-960h | ~360 MB | Speech feature extraction |
| LAM_audio2exp_streaming | ~500 MB | Audio to facial expression mapping |
| SenseVoiceSmall | ~500 MB | Speech-to-text (auto-downloads on first run) |

## Troubleshooting

**"CUDA out of memory"**: Reduce `concurrent_limit` in the config or use a smaller LLM.

**Browser shows connection error**: Accept the self-signed SSL certificate by navigating to `https://localhost:8282` directly.

**Audio not working**: Ensure your browser has microphone permissions. WebRTC requires HTTPS.

**Windows encoding errors**: Set `PYTHONUTF8=1` in your `.env` file.

**RTX 50-series GPUs**: Need CUDA 12.8+. Change the Dockerfile base image to `nvidia/cuda:12.8.0-cudnn9-devel-ubuntu22.04`.

## Project Structure

```
gaussian-avatar/
  docker-compose.yml      # Orchestrates avatar server + TURN
  Dockerfile              # Builds from OpenAvatarChat source
  .env.example            # API key template
  .gitignore              # Excludes models, certs, keys
  config/
    chat_with_lam.yaml    # Pipeline configuration
  scripts/
    setup.sh              # Downloads models + generates SSL
  models/                 # (created by setup.sh)
    wav2vec2-base-960h/
    LAM_audio2exp/
  ssl_certs/              # (created by setup.sh)
  coturn-data/            # (created by setup.sh)
```

## References

- [OpenAvatarChat](https://github.com/HumanAIGC-Engineering/OpenAvatarChat) — Apache-2.0
- [LAM: Large Avatar Model](https://github.com/aigc3d/LAM) — Apache-2.0 (SIGGRAPH 2025)
- [LAM Audio2Expression](https://github.com/aigc3d/LAM_Audio2Expression) — Real-time blendshapes from audio
- [LAM WebRender](https://github.com/nicedoc/nicedoc.io) — Browser Gaussian splatting renderer
