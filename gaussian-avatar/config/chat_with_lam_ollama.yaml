# =============================================================================
# OpenAvatarChat config â€” LAM Gaussian Avatar + Ollama (fully local, no API keys)
#
# Pipeline: SileroVAD -> SenseVoice ASR -> Ollama LLM -> EdgeTTS -> LAM Avatar
# Rendering: client-side Gaussian splatting in browser (WebGL)
#
# Prerequisites:
#   - Ollama running on host: ollama serve
#   - Model pulled: ollama pull llama3.2
#   - EdgeTTS: free, no API key needed
# =============================================================================

default:
  logger:
    log_level: "INFO"

  service:
    host: "0.0.0.0"
    port: 8282
    cert_file: "ssl_certs/localhost.crt"
    cert_key: "ssl_certs/localhost.key"

  chat_engine:
    model_root: "models"
    concurrent_limit: 3

    handler_search_path:
      - "src/handlers"

    handler_configs:
      LamClient:
        module: client/h5_rendering_client/client_handler_lam
        asset_path: "lam_samples/barbara.zip"
        connection_ttl: 900

      SileroVad:
        module: vad/silerovad/vad_handler_silero
        speaking_threshold: 0.5
        start_delay: 2048
        end_delay: 5000
        buffer_look_back: 5000
        speech_padding: 512

      SenseVoice:
        enabled: true
        module: asr/sensevoice/asr_handler_sensevoice
        model_name: "iic/SenseVoiceSmall"

      EdgeTTS:
        enabled: true
        module: tts/edgetts/tts_handler_edgetts
        voice: "en-US-AriaNeural"

      LLMOpenAICompatible:
        enabled: true
        module: llm/openai_compatible/llm_handler_openai_compatible
        model_name: "llama3.2"
        enable_video_input: false
        history_length: 20
        system_prompt: >
          You are a friendly digital human assistant having a face-to-face
          conversation. Keep your responses concise (2-3 sentences). Be warm,
          natural, and conversational. Use proper punctuation.
        api_url: "http://host.docker.internal:11434/v1"

      LAM_Driver:
        module: avatar/lam/avatar_handler_lam_audio2expression
